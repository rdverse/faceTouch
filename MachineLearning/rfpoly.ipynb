{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from csvLoader import get_data\n",
    "from Heuristics import get_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Few common functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def get_grid():\n",
    "    param_grid = {\n",
    "    'max_depth': [3, 5,10,20],\n",
    "    'min_samples_leaf': [5, 10,30,50,100, 150],\n",
    "    'min_samples_split': [10,20,30,50,100],\n",
    "    'n_estimators': [10,50,100,150,200,300],\n",
    "    #[int(x) for x in np.linspace(start=2, stop=20, num=1)],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "    rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "    grid_rf = RandomizedSearchCV(rf,\n",
    "                         param_grid,\n",
    "                          verbose=1,\n",
    "                           n_jobs=-1,\n",
    "                            cv=3,\n",
    "                            n_iter=300,\n",
    "                            random_state=11)\n",
    "\n",
    "    return grid_rf\n",
    "\n",
    "def evaluate(rfS, X_Train, X_Test,y_Train, y_Test):\n",
    "    testPreds = rfS.predict(X_Test)\n",
    "    trainPreds = rfS.predict(X_Train)\n",
    "    \n",
    "    classReportTest = classification_report(y_Test,testPreds, output_dict=True, target_names= [\"face\", \"non-face\"])\n",
    "    classReportTrain = classification_report(y_Train,trainPreds, output_dict=True, target_names= [\"face\", \"non-face\"])\n",
    "    \n",
    "    return classReportTest,classReportTrain\n",
    "    \n",
    "\n",
    "def _filter_cols( type=[[\"ag\"],[\"nr\"]]):\n",
    "    filterCols = list()\n",
    "\n",
    "    cols = get_labels()    \n",
    "    abbrev = {\"a\":\"accel\",\"g\":\"gyro\", \"r\":\"r\", \"n\":\"n\"}\n",
    "    typeCriteria = [[abbrev[tC] for tC in list(t[0])] for t in type]\n",
    "\n",
    "    # check and add resultant first\n",
    "    for sensor in typeCriteria[0]:\n",
    "        for axis in typeCriteria[1]:\n",
    "            if axis == \"r\":\n",
    "                filterCols.extend([c for c in cols if sensor in c.split(\"_\") and axis in c.split(\"_\")])\n",
    "            else:\n",
    "                filterCols.extend([c for c in cols if sensor in c.split(\"_\") and \"r\" not in c.split(\"_\")])\n",
    "    return filterCols\n",
    "\n",
    "def get_train_test_data(csvCode = \"50_8\", type=[[\"ag\"],[\"rn\"]]):\n",
    "\n",
    "    csvPATH =   \"../data/dataset/statFeatures/stat{}.csv\".format(csvCode)\n",
    "    data = get_data(PATH=csvPATH)\n",
    "    features, pids, descriptions, labels = data.features, data.pids, data.descriptions, data.labels\n",
    "    \n",
    "    filterCols = _filter_cols(type=type)\n",
    "    features = pd.DataFrame(features, columns = filterCols)\n",
    "    #features = features[filterCols]\n",
    "\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(features.values,\n",
    "                                    np.array(list(zip(pids,descriptions,labels))),\n",
    "                                    test_size=0.2,\n",
    "                                    shuffle=True,\n",
    "                                    random_state=11)\n",
    "\n",
    "    return filterCols, X_Train, X_Test, y_Train, y_Test\n",
    "\n",
    "\n",
    "def get_rcParams(plt):\n",
    "    plt.rcParams['font.size'] = 12\n",
    "\n",
    "    plt.rcParams['hatch.linewidth'] = 0.25\n",
    "\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "    plt.rcParams['figure.dpi'] = 600\n",
    "    plt.rcParams[\"lines.linewidth\"] = 1\n",
    "    plt.rcParams['hatch.linewidth'] = 0.15\n",
    "\n",
    "    return plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "a,b,c,d,e = get_train_test_data(csvCode=\"20_8\", type=[[\"ag\"],[\"rn\"]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############################################################\n",
      "../data/dataset/statFeatures/stat20_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat20_8.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "colNames, X_Train, X_Test, y_Train,y_Test = get_train_test_data(csvCode=\"80_8\", type = [[\"ag\"],[\"nr\"]])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############################################################\n",
      "../data/dataset/statFeatures/stat80_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat80_8.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "np.take(y_Train,2,axis=-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['0', '0', '1', ..., '1', '1', '0'], dtype='<U7')"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is the effect of window size on non-polynomial features ?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "testAccuracies = list()\n",
    "trainAccuracies = list()\n",
    "cvResults = list()\n",
    "for csvCode in [\"20_8\",\"30_8\",\"40_8\",\"50_8\",\"60_8\",\"70_8\",\"80_8\"]:\n",
    "    \n",
    "    colNames, X_Train, X_Test, y_Train,y_Test = get_train_test_data(csvCode=csvCode, type = [[\"ag\"],[\"nr\"]])\n",
    "    y_Trainl = np.take(y_Train,2,axis=-1)\n",
    "    y_Testl = np.take(y_Test,2,axis=-1)\n",
    "\n",
    "    grid_rf = get_grid()    \n",
    "    \n",
    "    #cvResult = cross_validate(rf, features, labels,cv=5)\n",
    "    #cvResults.append(cvResult)\n",
    "    grid_rf.fit(X_Train, y_Trainl)\n",
    "    rfBest = grid_rf.best_estimator_\n",
    "\n",
    "    classReportTest,classReportTrain =evaluate(rfBest, X_Train,X_Test, y_Trainl, y_Testl)\n",
    "\n",
    "    testAccuracies.append(classReportTest[\"accuracy\"])\n",
    "    trainAccuracies.append(classReportTrain[\"accuracy\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############################################################\n",
      "../data/dataset/statFeatures/stat20_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat20_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat30_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat30_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat40_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat40_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat50_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat50_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat60_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat60_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat70_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat70_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "############################################################\n",
      "../data/dataset/statFeatures/stat80_8.csv\n",
      "Data loaded from ../data/dataset/statFeatures/stat80_8.csv\n",
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "testAccuracies"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.8596491228070176,\n",
       " 0.8912280701754386,\n",
       " 0.9122807017543859,\n",
       " 0.8957845433255269,\n",
       " 0.9063231850117096,\n",
       " 0.9249706916764361,\n",
       " 0.9025821596244131]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Test accuracy for non-poly features is {} \".format(accuracy_score(y_Test, testPreds)*100))\n",
    "print(\"Train accuracy for non-poly features is {} \".format(accuracy_score(y_Train, trainPreds)*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfBest = grid_rf.best_estimator_\n",
    "rfBest.fit(X_Train[::,list(impDfSelect10.index)], y_Train)\n",
    "testPreds = rfBest.predict(X_TestPoly[::,list(impDfSelect10.index)])\n",
    "trainPreds = rfBest.predict(X_TrainPoly[::,list(impDfSelect10.index)])\n",
    "print(classification_report(y_Test, testPreds))\n",
    "print(\"Test accuracy for top 10 poly features is {} \".format(accuracy_score(y_Test, testPreds)*100))\n",
    "print(\"Train accuracy for top 10 poly features is {} \".format(accuracy_score(y_Train, trainPreds)*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols = get_labels()\n",
    "impDataSelect = np.array(list(zip(rfBestNorm.feature_importances_, cols)))\n",
    "\n",
    "impDfSelect = pd.DataFrame(impDataSelect, columns = [\"val\",\"feat\"]).sort_values(by=\"val\", ascending=False)\n",
    "\n",
    "impDfSelect10 = impDfSelect.sort_values(by=\"val\", ascending=False)[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfBestNorm.fit(X_Train[::,impDfSelect10.index],y_Train)\n",
    "testPreds = rfBestNorm.predict(X_Test[::,list(impDfSelect10.index)])\n",
    "trainPreds = rfBestNorm.predict(X_Train[::,list(impDfSelect10.index)])\n",
    "\n",
    "print(\"Test accuracy for top 10 non-poly features is {} \".format(accuracy_score(y_Test, testPreds)*100))\n",
    "print(\"Train accuracy for top 10 non-poly features is {} \".format(accuracy_score(y_Train, trainPreds)*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores = list()\n",
    "for selectItems in np.array(impDfSelectNorm.index).reshape(11,8):\n",
    "    rfNorm.fit(X_Train[::,selectItems],y_Train)\n",
    "    scores.append(accuracy_score(y_Test, rfNorm.predict(X_Test[::,selectItems])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[np.mean(r[\"train_score\"]) for r in cvResults]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "#fig, axs = plt.subplots(1,2, figsize = (4,2), dpi = 600)\n",
    "\n",
    "x = [\"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\",\"0.7\"]\n",
    "plt.plot(x,np.array(testAccuracies)*100, color = \"tab:blue\")\n",
    "plt.scatter(x,np.array(testAccuracies)*100)\n",
    "\n",
    "#plt.plot(x,testAccuracies, label=\"test\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.yticks([80,82,84,86,88,90],labels=[\"80%\",\"82%\",\"84%\",\"86%\",\"88%\",\"90%\"])\n",
    "#plt.plot(x,trainAccuracies, label = \"train\")\n",
    "#plt.legend()\n",
    "plt.savefig(\"windowSelect.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "poly  = PolynomialFeatures(2)\n",
    "poly = poly.fit(X_Train)\n",
    "\n",
    "X_TrainPoly = poly.transform(X_Train)\n",
    "X_TestPoly = poly.transform(X_Test)\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, verbose=0)\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5,10,20],\n",
    "    'min_samples_leaf': [5, 10,30,50,100, 150],\n",
    "    'min_samples_split': [10,20,30,50,100],\n",
    "    'n_estimators': [10,50,100,150,200,300],\n",
    "    #[int(x) for x in np.linspace(start=2, stop=20, num=1)],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# param_grid['pca__n_components'] = hyper['pca__n_components']\n",
    "#pipe = Pipeline([('poly',poly), ('rf', rf)])\n",
    "\n",
    "grid_rf = RandomizedSearchCV(rf,\n",
    "                         param_grid,\n",
    "                          verbose=1,\n",
    "                           n_jobs=-1,\n",
    "                            cv=3,\n",
    "                            n_iter=30)\n",
    "grid_rf.fit(X_TrainPoly, y_Train)\n",
    "print(grid_rf.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfBest = grid_rf.best_estimator_\n",
    "rfBest.fit(X_TrainPoly,y_Train)\n",
    "testPreds = rfBest.predict(X_TestPoly)\n",
    "print(classification_report(y_Test, testPreds))\n",
    "print(\"Test accuracy for poly features is {} \".format(accuracy_score(y_Test, testPreds)*100))\n",
    "print(\"Train accuracy for poly features is {} \".format(accuracy_score(y_Train, rfBest.predict(X_TrainPoly))*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(rfBest, X_TestPoly, y_Test)\n",
    "#plot_roc_curve(rfBestNorm,X_Test,y_Test)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.savefig(\"rocnonpoly.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols = get_labels()\n",
    "impDataSelect = np.array(list(zip(rfBest.feature_importances_, \n",
    "                        poly.get_feature_names(cols))))\n",
    "\n",
    "impDfSelect = pd.DataFrame(impDataSelect, columns = [\"val\",\"feat\"]).sort_values(by=\"val\", ascending=False)\n",
    "\n",
    "impDfSelect10 = impDfSelect.sort_values(by=\"val\", ascending=False)[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is the accuracy when rf is fit with top 10 polynomial features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfBest = grid_rf.best_estimator_\n",
    "rfBest.fit(X_TrainPoly[::,list(impDfSelect10.index)], y_Train)\n",
    "testPreds = rfBest.predict(X_TestPoly[::,list(impDfSelect10.index)])\n",
    "trainPreds = rfBest.predict(X_TrainPoly[::,list(impDfSelect10.index)])\n",
    "print(classification_report(y_Test, testPreds))\n",
    "print(\"Test accuracy for top 10 poly features is {} \".format(accuracy_score(y_Test, testPreds)*100))\n",
    "print(\"Train accuracy for top 10 poly features is {} \".format(accuracy_score(y_Train, trainPreds)*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tqdm\n",
    "scores = list()\n",
    "featuresInFocus = list()\n",
    "\n",
    "totalSpace = list(np.array(impDfSelect.index[:4000]).reshape(400,10))\n",
    "totalSpace.append(impDfSelect.index[4000:4005])\n",
    "\n",
    "for selectItems in tqdm.tqdm(totalSpace):\n",
    "    featuresInFocus.extend(selectItems)\n",
    "    rf.fit(X_TrainPoly[::,featuresInFocus],y_Train)\n",
    "    scores.append(accuracy_score(y_Test, rf.predict(X_TestPoly[::,featuresInFocus])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.rcParams['hatch.linewidth'] = 0.25\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams[\"lines.linewidth\"] = 1\n",
    "plt.rcParams['hatch.linewidth'] = 0.15\n",
    "\n",
    "#fig, axs = plt.subplots(1,2, figsize = (4,2), dpi = 600)\n",
    "\n",
    "#x = [\"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\",\"0.7\"]\n",
    "cFeats = list(np.linspace(10,4000,400))\n",
    "cFeats.append(4005)\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.plot(cFeats[0:], (np.array(scores)*100)[0:], color = \"tab:blue\")\n",
    "#plt.scatter(cFeats,np.array(scores)*100)\n",
    "\n",
    "#plt.plot(x,testAccuracies, label=\"test\")\n",
    "ax.set_xlabel(\"Features used\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "#yl = [86,87,88,89,90,91,92]\n",
    "#plt.yticks(yl,labels=[str(l) + \"%\" for l in yl])\n",
    "#plt.plot(x,trainAccuracies, label = \"train\")\n",
    "#plt.legend()\n",
    "#ax.set_ylabel(ax.yaxis.majorTicks)\n",
    "def format_func(value,ticknumber):\n",
    "    return str(value) + \"%\"\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "\n",
    "plt.savefig(\"selectPoly10.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax.yaxis.majorTicks[0].__dict__.keys()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfSmall = RandomForestClassifier(max_depth = 10, n_estimators = 200)\n",
    "rfSmall.fit(X_TrainPoly[::,impDfSelect10.index],y_Train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfSmall.score(X_TestPoly[::,impDfSelect10.index],y_Test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rf = RandomForestClassifier(n_estimators= 100, \n",
    "#                             min_samples_split= 10,\n",
    "#                              min_samples_leaf= 5, \n",
    "#                              max_features= 'auto',\n",
    "#                               max_depth= 10, \n",
    "#                               bootstrap= False)\n",
    "# rf.fit(X_TrainPoly, y_Train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.rcParams['hatch.linewidth'] = 0.25\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams[\"lines.linewidth\"] = 1\n",
    "plt.rcParams['hatch.linewidth'] = 0.15\n",
    "# plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize= (7.0,3))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.barh(impDfSelect[\"feat\"].values,impDfSelect[\"val\"].values)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rfImportancePoly.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores = list()\n",
    "featuresInFocus = list()\n",
    "for selectItems in np.array(impDfSelect.index).reshape(4005,100):\n",
    "    featuresInFocus.extend(selectItems)\n",
    "    rf.fit(X_TrainPoly[::,featuresInFocus],y_Train)\n",
    "    scores.append(accuracy_score(y_Test, rf.predict(X_TestPoly[::,featuresInFocus])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfNorm = RandomForestClassifier(n_estimators= 100, \n",
    "                            min_samples_split= 10,\n",
    "                             min_samples_leaf= 5, \n",
    "                             max_features= 'auto',\n",
    "                              max_depth= 10, \n",
    "                              bootstrap= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfNorm.fit(X_Train, y_Train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(rf.predict(X_Test), y_Test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "impData = np.array(list(zip(rfNorm.feature_importances_, cols)))\n",
    "impDfNorm = pd.DataFrame(impData, columns = [\"val\",\"feat\"])\n",
    "#impDfSelectNorm= impDfNorm.sort_values(by=\"val\", ascending=False)[:10]\n",
    "impDfSelectNorm= impDfNorm.sort_values(by=\"val\", ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores = list()\n",
    "for selectItems in np.array(impDfSelectNorm.index).reshape(11,8):\n",
    "    rfNorm.fit(X_Train[::,selectItems],y_Train)\n",
    "    scores.append(accuracy_score(y_Test, rfNorm.predict(X_Test[::,selectItems])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = plt.subplot()\n",
    "ax.barh(impDfSelect[\"feat\"].values,impDfSelect[\"val\"].values)\n",
    "#.xticks(FormatStrFormatter('%.2f'))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipe['poly'].get_feature_names(cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Heuristics import get_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols = get_labels()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('facePy': conda)"
  },
  "interpreter": {
   "hash": "c39a2619ac667b8116ef4989c7433e85b59243eb4a825554e252b96c371cd590"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}