{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#go through each file\n",
    "#clean_PATH\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample the data to 50Hz @later\n",
    "labels = list()\n",
    "Features = list()\n",
    "\n",
    "#data_prep = pd.DataFrame(columns = ['Accel_WR_X_CAL','Accel_WR_Y_CAL','Accel_WR_Z_CAL','Activity'])\n",
    "# prepare dataset sliding windwos but no overlap\n",
    "PATH = '../data/p1'\n",
    "for instance in os.listdir(PATH):\n",
    "    \n",
    "    instance_df = pd.read_csv(PATH + '/' +instance)\n",
    "    instance_df.reset_index(drop = True, inplace = True)\n",
    "    for i in np.linspace(0,14.9,150):\n",
    "        #print(i)\n",
    "        inst_df = instance_df.loc[i*200:(i+0.1)*200]\n",
    "        inst_df.reset_index(drop = True, inplace = True)\n",
    "        inst_df = inst_df[0:20]\n",
    "        #print(inst_df.shape)\n",
    "        labels.append(instance[:-4])\n",
    "        feat_x = inst_df['Accel_WR_X_CAL']\n",
    "        feat_y = inst_df['Accel_WR_Y_CAL']\n",
    "        feat_z = inst_df['Accel_WR_Z_CAL']\n",
    "        feat_xyz = np.array([feat_x,feat_y,feat_z]).flatten()\n",
    "        #print(feat_xyz.shape)\n",
    "        Features.append(feat_xyz)\n",
    "\n",
    "labels = np.array(labels)\n",
    "Features = np.array(Features)\n",
    "\n",
    "#train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ,  1.25,  1.5 ,  1.75,  2.  ,\n",
       "        2.25,  2.5 ,  2.75,  3.  ,  3.25,  3.5 ,  3.75,  4.  ,  4.25,\n",
       "        4.5 ,  4.75,  5.  ,  5.25,  5.5 ,  5.75,  6.  ,  6.25,  6.5 ,\n",
       "        6.75,  7.  ,  7.25,  7.5 ,  7.75,  8.  ,  8.25,  8.5 ,  8.75,\n",
       "        9.  ,  9.25,  9.5 ,  9.75, 10.  , 10.25, 10.5 , 10.75, 11.  ,\n",
       "       11.25, 11.5 , 11.75, 12.  , 12.25, 12.5 , 12.75, 13.  , 13.25,\n",
       "       13.5 , 13.75, 14.  , 14.25, 14.5 , 14.75, 15.  , 15.25, 15.5 ,\n",
       "       15.75, 16.  , 16.25, 16.5 , 16.75, 17.  , 17.25, 17.5 , 17.75,\n",
       "       18.  , 18.25, 18.5 , 18.75, 19.  , 19.25, 19.5 , 19.75])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,19.75,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = KMeans(n_clusters = 4).fit(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1407.,    0.,    0.,  580.,    0.,    0.,  311.,    0.,    0.,\n",
       "         402.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clust.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       " <a list of 18 Text xticklabel objects>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(labels,clust.labels_)\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-87bb3e2f2534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtouch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'walking_upstairs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group_df' is not defined"
     ]
    }
   ],
   "source": [
    "touch = group_df.get_group('walking_upstairs')\n",
    "touch.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "Featurest = list()\n",
    "count = 0\n",
    "Labelst = list()\n",
    "for instance in os.listdir(PATH):\n",
    "    instance_df = pd.read_csv(PATH + '/' +instance)\n",
    "    instance_df.reset_index(drop = True, inplace = True)\n",
    "    for i in np.linspace(15,20,50):\n",
    "        #print(i)\n",
    "        inst_df = instance_df.loc[i*200:(i+0.1)*200]\n",
    "        inst_df.reset_index(drop = True, inplace = True)\n",
    "        inst_df = inst_df[0:20]\n",
    "\n",
    "        #labels.append(instance[:-4])\n",
    "        feat_x = inst_df['Accel_WR_X_CAL']\n",
    "        feat_y = inst_df['Accel_WR_Y_CAL']\n",
    "        feat_z = inst_df['Accel_WR_Z_CAL']\n",
    "        feat_xyz = np.array([feat_x,feat_y,feat_z]).flatten()\n",
    "        #print(feat_xyz)\n",
    "        #Featurest = list(Featurest)\n",
    "        Featurest.append(feat_xyz)\n",
    "        Labelst.append(int(instance[:-4]))\n",
    "        #Featurest = np.array(Featurest)\n",
    "        #print(clust.predict(Featurest[count].reshape(1,-1)))\n",
    "        count = count+1\n",
    "Featurest = np.array(Featurest)\n",
    "#print(clust.predict(Featurest))\n",
    "print(len(Labelst)/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true along y axis and predicted on x axis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>17.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0    1.0   2.0    3.0   4.0   5.0   6.0   7.0   8.0   9.0   10.0  11.0  \\\n",
       "0     0.0    0.0   0.0  100.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   100.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2     0.0    0.0   0.0  100.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3    24.0   56.0  18.0    2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4    54.0   36.0  10.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "5    28.0   60.0  12.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6    26.0   60.0  14.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7    26.0   62.0  12.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8    26.0   60.0  14.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9    78.0    0.0   4.0   18.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "10    0.0  100.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "11  100.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "12  100.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "13  100.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "14  100.0    0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "15   72.0    0.0  26.0    2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "16   32.0    0.0  68.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "17   48.0    8.0  14.0   30.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    12.0  13.0  14.0  15.0  16.0  17.0  \n",
       "0    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "8    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "9    0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "10   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "11   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "12   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "13   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "14   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "15   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "16   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17   0.0   0.0   0.0   0.0   0.0   0.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.zeros(shape = (18,18))\n",
    "Labelst = Labelst - np.ones(len(Labelst))\n",
    "confusion_df = pd.DataFrame(data,columns = list(set(Labelst)))\n",
    "predict_matrix = pd.DataFrame(list(zip(Labelst, clust.predict(Featurest))), columns = ['true', 'pred'])\n",
    "group_predicts = predict_matrix.groupby('true')\n",
    "\n",
    "for group in group_predicts.groups:\n",
    "    temp_df = group_predicts.get_group(group)['pred'].value_counts().reset_index()\n",
    "    temp_df.columns = ['col', 'count']\n",
    "    \n",
    "    for col in temp_df['col']:\n",
    "        confusion_df.iloc[int(group)][col] = temp_df[temp_df['col']== col]['count']\n",
    "    \n",
    "for key in list(set(Labelst)):\n",
    "    confusion_df[key] = round((confusion_df[key]/50)*100,2)\n",
    "\n",
    "print('true along y axis and predicted on x axis')\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_matrix = pd.DataFrame(list(zip(Labelst, clust.predict(Featurest))), columns = ['true', 'pred'])\n",
    "group_predicts = predict_matrix.groupby('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(confusion_matrix(predict_matrix['true'],predict_matrix['pred']),cmap=plt.get_cmap('viridis'), alpha = 0.9)\n",
    "plt.xticks(np.linspace(0,17,18))\n",
    "plt.yticks(np.linspace(0,17,18))\n",
    "\n",
    "plt.title('Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clust.predict(Featurest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/p3'\n",
    "FeaturesC = list()\n",
    "count = 0\n",
    "LabelsC = list()\n",
    "for instance in os.listdir(PATH):\n",
    "    instance_df = pd.read_csv(PATH + '/' +instance)\n",
    "    instance_df.reset_index(drop = True, inplace = True)\n",
    "    for i in np.linspace(0,20,200):\n",
    "        inst_df = instance_df.loc[i*200:(i+0.1)*200]\n",
    "        inst_df.reset_index(drop = True, inplace = True)\n",
    "        inst_df = inst_df[0:20]\n",
    "        \n",
    "        feat_x = inst_df['Accel_WR_X_CAL']\n",
    "        feat_y = inst_df['Accel_WR_Y_CAL']\n",
    "        feat_z = inst_df['Accel_WR_Z_CAL']\n",
    "        feat_xyz = np.array([feat_x,feat_y,feat_z]).flatten()\n",
    "        \n",
    "        FeaturesC.append(feat_xyz)\n",
    "        \n",
    "        if int(instance[:-4]) in [4,5,6,7,8,9]:\n",
    "            LabelsC.append('touch')\n",
    "        \n",
    "        else:\n",
    "            LabelsC.append('no touch')\n",
    "            \n",
    "        count = count+1\n",
    "FeaturesC = np.array(FeaturesC)\n",
    "#print(clust.predict(Featurest))\n",
    "print(len(LabelsC)/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.220096</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>2.373206</td>\n",
       "      <td>2.449761</td>\n",
       "      <td>2.488038</td>\n",
       "      <td>2.583732</td>\n",
       "      <td>2.755981</td>\n",
       "      <td>2.794258</td>\n",
       "      <td>2.813397</td>\n",
       "      <td>2.928230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244019</td>\n",
       "      <td>1.244019</td>\n",
       "      <td>1.320574</td>\n",
       "      <td>1.282297</td>\n",
       "      <td>1.320574</td>\n",
       "      <td>1.377990</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>1.492823</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>1.550239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.851675</td>\n",
       "      <td>2.851675</td>\n",
       "      <td>2.889952</td>\n",
       "      <td>2.775120</td>\n",
       "      <td>2.755981</td>\n",
       "      <td>2.736842</td>\n",
       "      <td>2.717703</td>\n",
       "      <td>2.583732</td>\n",
       "      <td>2.679426</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.799043</td>\n",
       "      <td>1.645933</td>\n",
       "      <td>1.588517</td>\n",
       "      <td>1.492823</td>\n",
       "      <td>1.377990</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.186603</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.760766</td>\n",
       "      <td>1.799043</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.875598</td>\n",
       "      <td>1.894737</td>\n",
       "      <td>1.952153</td>\n",
       "      <td>2.143541</td>\n",
       "      <td>2.277512</td>\n",
       "      <td>2.430622</td>\n",
       "      <td>2.468900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.918660</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.937799</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.014354</td>\n",
       "      <td>1.014354</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>0.995215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.851675</td>\n",
       "      <td>2.985646</td>\n",
       "      <td>3.023923</td>\n",
       "      <td>3.100478</td>\n",
       "      <td>3.196172</td>\n",
       "      <td>3.253589</td>\n",
       "      <td>3.406699</td>\n",
       "      <td>3.464115</td>\n",
       "      <td>3.598086</td>\n",
       "      <td>3.770335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071770</td>\n",
       "      <td>1.339713</td>\n",
       "      <td>1.435407</td>\n",
       "      <td>1.665072</td>\n",
       "      <td>1.837321</td>\n",
       "      <td>1.875598</td>\n",
       "      <td>2.047847</td>\n",
       "      <td>2.162679</td>\n",
       "      <td>2.296651</td>\n",
       "      <td>2.334928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.789474</td>\n",
       "      <td>3.598086</td>\n",
       "      <td>3.444976</td>\n",
       "      <td>3.368421</td>\n",
       "      <td>3.196172</td>\n",
       "      <td>3.215311</td>\n",
       "      <td>3.119617</td>\n",
       "      <td>3.119617</td>\n",
       "      <td>3.081340</td>\n",
       "      <td>3.043062</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933014</td>\n",
       "      <td>1.894737</td>\n",
       "      <td>1.913876</td>\n",
       "      <td>1.952153</td>\n",
       "      <td>1.952153</td>\n",
       "      <td>2.028708</td>\n",
       "      <td>2.028708</td>\n",
       "      <td>2.086124</td>\n",
       "      <td>2.277512</td>\n",
       "      <td>2.296651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>2.564593</td>\n",
       "      <td>2.679426</td>\n",
       "      <td>2.583732</td>\n",
       "      <td>2.468900</td>\n",
       "      <td>2.488038</td>\n",
       "      <td>2.507177</td>\n",
       "      <td>2.468900</td>\n",
       "      <td>2.430622</td>\n",
       "      <td>2.449761</td>\n",
       "      <td>2.373206</td>\n",
       "      <td>...</td>\n",
       "      <td>6.105263</td>\n",
       "      <td>6.086124</td>\n",
       "      <td>6.086124</td>\n",
       "      <td>6.086124</td>\n",
       "      <td>6.086124</td>\n",
       "      <td>6.066986</td>\n",
       "      <td>6.047847</td>\n",
       "      <td>6.066986</td>\n",
       "      <td>6.066986</td>\n",
       "      <td>6.086124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.799043</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.837321</td>\n",
       "      <td>1.933014</td>\n",
       "      <td>2.086124</td>\n",
       "      <td>2.220096</td>\n",
       "      <td>2.277512</td>\n",
       "      <td>2.143541</td>\n",
       "      <td>2.047847</td>\n",
       "      <td>...</td>\n",
       "      <td>6.354067</td>\n",
       "      <td>6.392344</td>\n",
       "      <td>6.296651</td>\n",
       "      <td>6.334928</td>\n",
       "      <td>6.258373</td>\n",
       "      <td>6.162679</td>\n",
       "      <td>6.200957</td>\n",
       "      <td>6.162679</td>\n",
       "      <td>6.200957</td>\n",
       "      <td>6.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>2.047847</td>\n",
       "      <td>2.009569</td>\n",
       "      <td>1.837321</td>\n",
       "      <td>1.722488</td>\n",
       "      <td>1.626794</td>\n",
       "      <td>1.531100</td>\n",
       "      <td>1.531100</td>\n",
       "      <td>1.511962</td>\n",
       "      <td>1.511962</td>\n",
       "      <td>1.607656</td>\n",
       "      <td>...</td>\n",
       "      <td>6.354067</td>\n",
       "      <td>6.296651</td>\n",
       "      <td>6.296651</td>\n",
       "      <td>6.296651</td>\n",
       "      <td>6.277512</td>\n",
       "      <td>6.239234</td>\n",
       "      <td>6.334928</td>\n",
       "      <td>6.200957</td>\n",
       "      <td>6.277512</td>\n",
       "      <td>6.239234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>1.301435</td>\n",
       "      <td>1.358852</td>\n",
       "      <td>1.377990</td>\n",
       "      <td>1.397129</td>\n",
       "      <td>1.397129</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>1.511962</td>\n",
       "      <td>1.511962</td>\n",
       "      <td>1.435407</td>\n",
       "      <td>...</td>\n",
       "      <td>6.507177</td>\n",
       "      <td>6.468900</td>\n",
       "      <td>6.468900</td>\n",
       "      <td>6.411483</td>\n",
       "      <td>6.507177</td>\n",
       "      <td>6.373206</td>\n",
       "      <td>6.334928</td>\n",
       "      <td>6.200957</td>\n",
       "      <td>6.124402</td>\n",
       "      <td>6.086124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>1.110048</td>\n",
       "      <td>1.244019</td>\n",
       "      <td>1.282297</td>\n",
       "      <td>1.358852</td>\n",
       "      <td>1.282297</td>\n",
       "      <td>1.148325</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>0.937799</td>\n",
       "      <td>0.918660</td>\n",
       "      <td>...</td>\n",
       "      <td>6.564593</td>\n",
       "      <td>6.622010</td>\n",
       "      <td>6.564593</td>\n",
       "      <td>6.411483</td>\n",
       "      <td>6.449761</td>\n",
       "      <td>6.354067</td>\n",
       "      <td>6.277512</td>\n",
       "      <td>6.258373</td>\n",
       "      <td>6.277512</td>\n",
       "      <td>6.296651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     2.220096  2.315789  2.373206  2.449761  2.488038  2.583732  2.755981   \n",
       "1     2.851675  2.851675  2.889952  2.775120  2.755981  2.736842  2.717703   \n",
       "2     1.760766  1.799043  1.818182  1.875598  1.894737  1.952153  2.143541   \n",
       "3     2.851675  2.985646  3.023923  3.100478  3.196172  3.253589  3.406699   \n",
       "4     3.789474  3.598086  3.444976  3.368421  3.196172  3.215311  3.119617   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3595  2.564593  2.679426  2.583732  2.468900  2.488038  2.507177  2.468900   \n",
       "3596  1.818182  1.799043  1.818182  1.837321  1.933014  2.086124  2.220096   \n",
       "3597  2.047847  2.009569  1.837321  1.722488  1.626794  1.531100  1.531100   \n",
       "3598  1.301435  1.358852  1.377990  1.397129  1.397129  1.473684  1.454545   \n",
       "3599  1.110048  1.244019  1.282297  1.358852  1.282297  1.148325  1.033493   \n",
       "\n",
       "            7         8         9   ...        50        51        52  \\\n",
       "0     2.794258  2.813397  2.928230  ...  1.244019  1.244019  1.320574   \n",
       "1     2.583732  2.679426  2.526316  ...  1.799043  1.645933  1.588517   \n",
       "2     2.277512  2.430622  2.468900  ...  0.727273  0.918660  0.899522   \n",
       "3     3.464115  3.598086  3.770335  ...  1.071770  1.339713  1.435407   \n",
       "4     3.119617  3.081340  3.043062  ...  1.933014  1.894737  1.913876   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3595  2.430622  2.449761  2.373206  ...  6.105263  6.086124  6.086124   \n",
       "3596  2.277512  2.143541  2.047847  ...  6.354067  6.392344  6.296651   \n",
       "3597  1.511962  1.511962  1.607656  ...  6.354067  6.296651  6.296651   \n",
       "3598  1.511962  1.511962  1.435407  ...  6.507177  6.468900  6.468900   \n",
       "3599  0.956938  0.937799  0.918660  ...  6.564593  6.622010  6.564593   \n",
       "\n",
       "            53        54        55        56        57        58        59  \n",
       "0     1.282297  1.320574  1.377990  1.454545  1.492823  1.473684  1.550239  \n",
       "1     1.492823  1.377990  1.263158  1.186603  1.033493  0.899522  0.842105  \n",
       "2     0.937799  1.033493  1.090909  1.014354  1.014354  0.956938  0.995215  \n",
       "3     1.665072  1.837321  1.875598  2.047847  2.162679  2.296651  2.334928  \n",
       "4     1.952153  1.952153  2.028708  2.028708  2.086124  2.277512  2.296651  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3595  6.086124  6.086124  6.066986  6.047847  6.066986  6.066986  6.086124  \n",
       "3596  6.334928  6.258373  6.162679  6.200957  6.162679  6.200957  6.181818  \n",
       "3597  6.296651  6.277512  6.239234  6.334928  6.200957  6.277512  6.239234  \n",
       "3598  6.411483  6.507177  6.373206  6.334928  6.200957  6.124402  6.086124  \n",
       "3599  6.411483  6.449761  6.354067  6.277512  6.258373  6.277512  6.296651  \n",
       "\n",
       "[3600 rows x 60 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(FeaturesC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,  X_test,y_train, y_test = train_test_split(FeaturesC, LabelsC,  test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no touch       0.74      0.98      0.84       474\n",
      "       touch       0.91      0.32      0.47       246\n",
      "\n",
      "    accuracy                           0.76       720\n",
      "   macro avg       0.82      0.65      0.66       720\n",
      "weighted avg       0.79      0.76      0.71       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "reg = LogisticRegressionCV(cv=5,max_iter = 1000)\n",
    "model = reg.fit(X_train, y_train)\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [6, 10,100],\n",
    "    'min_samples_leaf': [3, 5],\n",
    "    'min_samples_split': [20,25],\n",
    "    'n_estimators': [50,100,250]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator = clf, param_grid = param_grid, cv=3,verbose=1,scoring = 'f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.761, total=   1.0s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.788, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.765, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.766, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.788, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.768, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.766, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.786, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.759, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.761, total=   0.3s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.783, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.761, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.756, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.792, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.752, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.761, total=   1.0s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.784, total=   0.7s\n",
      "[CV] max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.759, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.757, total=   0.3s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.789, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.757, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.768, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.786, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.749, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.768, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.787, total=   0.9s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.774, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.756, total=   0.3s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.786, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.756, total=   0.4s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.761, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.780, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.757, total=   0.5s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.757, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.785, total=   0.8s\n",
      "[CV] max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=6, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.761, total=   0.8s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.806, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.799, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.790, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.812, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.793, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.797, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.812, total=   1.1s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.802, total=   1.1s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.797, total=   1.1s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.813, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.796, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.791, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.801, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.799, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.793, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.813, total=   1.0s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.792, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.792, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.807, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.801, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.794, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.809, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.796, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.799, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.809, total=   1.2s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.797, total=   1.1s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.796, total=   1.0s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.812, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.801, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.795, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.798, total=   0.5s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.797, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.796, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.804, total=   1.0s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.796, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=10, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.796, total=   1.0s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.818, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.804, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=50, score=0.791, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.819, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.803, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=100, score=0.787, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.815, total=   1.6s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.806, total=   1.7s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=20, n_estimators=250, score=0.793, total=   1.8s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.822, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.808, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=50, score=0.799, total=   0.6s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.816, total=   0.8s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.805, total=   0.9s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=100, score=0.792, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.812, total=   2.0s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.801, total=   1.6s\n",
      "[CV] max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=3, min_samples_split=25, n_estimators=250, score=0.792, total=   1.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.815, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.805, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=50, score=0.792, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.811, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.807, total=   0.7s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=100, score=0.785, total=   0.6s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.818, total=   1.2s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.799, total=   1.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=20, n_estimators=250, score=0.787, total=   1.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.811, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.794, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=50, score=0.784, total=   0.4s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.813, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.801, total=   0.5s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=100, score=0.791, total=   0.6s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.818, total=   1.2s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.799, total=   1.0s\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250 \n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=25, n_estimators=250, score=0.797, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [6, 10, 100], 'min_samples_leaf': [3, 5],\n",
       "                         'min_samples_split': [20, 25],\n",
       "                         'n_estimators': [50, 100, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no touch       0.87      0.92      0.89       474\n",
      "       touch       0.83      0.74      0.78       246\n",
      "\n",
      "    accuracy                           0.86       720\n",
      "   macro avg       0.85      0.83      0.84       720\n",
      "weighted avg       0.86      0.86      0.85       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_grid.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=100, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=25,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
