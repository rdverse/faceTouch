{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initi\n",
    "    # alized.\n",
    "    print('Could not initialize the tensorflow gpu')\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "identifiers = np.loadtxt(\"labels50.txt\", dtype=\"str\")\n",
    "features = np.loadtxt(\"features50.txt\")\n",
    "labels = np.take(identifiers,2, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "labels = labels.astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "features[0][0:6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([   7.38043478,    6.9673913 ,   -5.08695652, -205.73170732,\n",
       "         39.14634146, -153.01829268])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "features = features.reshape(4272,50,6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "input = layers.Input(shape = (50,6))\n",
    "#model = layers.Conv1D(50, kernel_size = 6, activation='relu')(input)\n",
    "model = layers.LSTM(100)(input)\n",
    "model = layers.GlobalAveragePooling1D()(model)\n",
    "#model = layers.Flatten()(model)\n",
    "model = layers.Dense(100)(model)\n",
    "output = layers.Dense(1, 'sigmoid')(model)\n",
    "model = tf.keras.Model(inputs=[input], outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(loss = loss, optimizer=optimizer, metrics = ['accuracy'])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input 0 of layer global_average_pooling1d_12 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4616/496824867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = layers.Conv1D(50, kernel_size = 6, activation='relu')(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model = layers.Flatten()(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2682\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2684\u001b[0;31m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[1;32m   2685\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facePy/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    220\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer global_average_pooling1d_12 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "X_Train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3417, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "hist = model.fit(X_Train.reshape(len(X_Train), 50,6),y_Train, epochs=100, shuffle=True,validation_split=0.2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 3.1640 - accuracy: 0.5540 - val_loss: 0.8145 - val_accuracy: 0.6126\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 1.0513 - accuracy: 0.6058 - val_loss: 1.0144 - val_accuracy: 0.5980\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.9418 - accuracy: 0.6120 - val_loss: 0.8665 - val_accuracy: 0.6389\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.6155 - val_loss: 0.8179 - val_accuracy: 0.6243\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.7914 - accuracy: 0.6612 - val_loss: 0.6726 - val_accuracy: 0.6564\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.8701 - accuracy: 0.6078 - val_loss: 0.7113 - val_accuracy: 0.6740\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6631 - val_loss: 0.7131 - val_accuracy: 0.6491\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6526 - val_loss: 0.5978 - val_accuracy: 0.6857\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6417 - val_loss: 0.6146 - val_accuracy: 0.6915\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6618 - val_loss: 0.6142 - val_accuracy: 0.6784\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.6648 - val_loss: 0.6354 - val_accuracy: 0.6608\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.6790 - val_loss: 0.7081 - val_accuracy: 0.6184\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.6322 - val_loss: 0.6281 - val_accuracy: 0.6696\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6882 - val_loss: 0.6469 - val_accuracy: 0.6871\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.6757 - val_loss: 0.5782 - val_accuracy: 0.7208\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.6700 - val_loss: 0.5685 - val_accuracy: 0.6959\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6766 - val_loss: 0.5942 - val_accuracy: 0.7193\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6781 - val_loss: 0.5755 - val_accuracy: 0.7266\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6830 - val_loss: 0.7133 - val_accuracy: 0.6974\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.6928 - val_loss: 0.5881 - val_accuracy: 0.7193\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6980 - val_loss: 0.5511 - val_accuracy: 0.7412\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.7076 - val_loss: 0.6651 - val_accuracy: 0.7266\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6889 - val_loss: 0.5482 - val_accuracy: 0.7661\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.7265 - val_loss: 0.5951 - val_accuracy: 0.6813\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.6972 - val_loss: 0.5236 - val_accuracy: 0.7807\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7237 - val_loss: 0.5969 - val_accuracy: 0.7193\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7253 - val_loss: 0.5320 - val_accuracy: 0.7485\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.7306 - val_loss: 0.5794 - val_accuracy: 0.7018\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7193 - val_loss: 0.5503 - val_accuracy: 0.7544\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7443 - val_loss: 0.6264 - val_accuracy: 0.7339\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.7172 - val_loss: 0.5483 - val_accuracy: 0.7558\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.7241 - val_loss: 0.5228 - val_accuracy: 0.7749\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7345 - val_loss: 0.5825 - val_accuracy: 0.7281\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.7289 - val_loss: 0.5146 - val_accuracy: 0.7661\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7486 - val_loss: 0.5247 - val_accuracy: 0.7836\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7496 - val_loss: 0.5358 - val_accuracy: 0.7865\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7416 - val_loss: 0.4907 - val_accuracy: 0.7997\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7479 - val_loss: 0.6365 - val_accuracy: 0.6725\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7226 - val_loss: 0.5163 - val_accuracy: 0.7544\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7460 - val_loss: 0.5779 - val_accuracy: 0.7383\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7349 - val_loss: 0.5748 - val_accuracy: 0.7164\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7463 - val_loss: 0.5424 - val_accuracy: 0.7675\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7371 - val_loss: 0.5120 - val_accuracy: 0.7763\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7499 - val_loss: 0.5267 - val_accuracy: 0.7690\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.7207 - val_loss: 0.5807 - val_accuracy: 0.7237\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.7301 - val_loss: 0.5602 - val_accuracy: 0.7632\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7591 - val_loss: 0.5427 - val_accuracy: 0.7602\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7408 - val_loss: 0.4810 - val_accuracy: 0.7982\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7342 - val_loss: 0.5126 - val_accuracy: 0.7822\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.7309 - val_loss: 0.4802 - val_accuracy: 0.7792\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7623 - val_loss: 0.6080 - val_accuracy: 0.7237\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7483 - val_loss: 0.5894 - val_accuracy: 0.7339\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7488 - val_loss: 0.5846 - val_accuracy: 0.7529\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7482 - val_loss: 0.5098 - val_accuracy: 0.7690\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7506 - val_loss: 0.5015 - val_accuracy: 0.7456\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.7539 - val_loss: 0.5312 - val_accuracy: 0.7588\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7551 - val_loss: 0.4879 - val_accuracy: 0.7924\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.7501 - val_loss: 0.4761 - val_accuracy: 0.7836\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7577 - val_loss: 0.5386 - val_accuracy: 0.7734\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7573 - val_loss: 0.4826 - val_accuracy: 0.7734\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7491 - val_loss: 0.5667 - val_accuracy: 0.7661\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7554 - val_loss: 0.5803 - val_accuracy: 0.6857\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7550 - val_loss: 0.5212 - val_accuracy: 0.7632\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7428 - val_loss: 0.4896 - val_accuracy: 0.7749\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7765 - val_loss: 0.5190 - val_accuracy: 0.7865\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7566 - val_loss: 0.5150 - val_accuracy: 0.7792\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7505 - val_loss: 0.4833 - val_accuracy: 0.7924\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7603 - val_loss: 0.4776 - val_accuracy: 0.7792\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7583 - val_loss: 0.4849 - val_accuracy: 0.7997\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7559 - val_loss: 0.5195 - val_accuracy: 0.7734\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7880\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7490 - val_loss: 0.4735 - val_accuracy: 0.7822\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7658 - val_loss: 0.4982 - val_accuracy: 0.7822\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7706 - val_loss: 0.5052 - val_accuracy: 0.8012\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7665 - val_loss: 0.4779 - val_accuracy: 0.7968\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7547 - val_loss: 0.5027 - val_accuracy: 0.8070\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7656 - val_loss: 0.4774 - val_accuracy: 0.7968\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7648 - val_loss: 0.4695 - val_accuracy: 0.7822\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7845 - val_loss: 0.4900 - val_accuracy: 0.8070\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7684 - val_loss: 0.4376 - val_accuracy: 0.8406\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7911 - val_loss: 0.4998 - val_accuracy: 0.7851\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7661 - val_loss: 0.5024 - val_accuracy: 0.7939\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7733 - val_loss: 0.5508 - val_accuracy: 0.7471\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7643 - val_loss: 0.5024 - val_accuracy: 0.7924\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7596 - val_loss: 0.4555 - val_accuracy: 0.8085\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7748 - val_loss: 0.5231 - val_accuracy: 0.7661\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7832 - val_loss: 0.4497 - val_accuracy: 0.7953\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7790 - val_loss: 0.4931 - val_accuracy: 0.7734\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7710 - val_loss: 0.4691 - val_accuracy: 0.8012\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7646 - val_loss: 0.4611 - val_accuracy: 0.8143\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7613 - val_loss: 0.4688 - val_accuracy: 0.7617\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7894 - val_loss: 0.4352 - val_accuracy: 0.8202\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7675\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7851 - val_loss: 0.4307 - val_accuracy: 0.8129\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7811 - val_loss: 0.5505 - val_accuracy: 0.7354\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7516 - val_loss: 0.4313 - val_accuracy: 0.8085\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.8004 - val_loss: 0.4784 - val_accuracy: 0.7997\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7968\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7827 - val_loss: 0.5549 - val_accuracy: 0.7339\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7717 - val_loss: 0.4678 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "preds = [1 if p > 0.5 else 0 for p in model.predict(X_Test.reshape(len(X_Test), 50,6))]\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy_score(y_Test,preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7461988304093568"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# from collections import Counter \n",
    "\n",
    "# Counter(preds)\n",
    "# print(classification_report(labels, preds))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "model.summary( )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 50, 6)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 45, 50)            1850      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 7,051\n",
      "Trainable params: 7,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "flatFeatures = features.flatten().reshape(4272,300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(flatFeatures, labels, random_state=43, test_size=0.2, shuffle=True)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "\n",
    "rf.fit(X_Train, y_Train)\n",
    "\n",
    "rf.score(X_Test,y_Test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7076023391812866"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('facePy': conda)"
  },
  "interpreter": {
   "hash": "c39a2619ac667b8116ef4989c7433e85b59243eb4a825554e252b96c371cd590"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}