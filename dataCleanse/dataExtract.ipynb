{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Script for Cleaning raw files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import  Counter\n",
    "from IPython.display import clear_output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def copy_PATH(src  = '/media/rdverse/Hippocampus/faceData/data', dest = '.'):\n",
    "    \"\"\" create a link for data path in current dir\n",
    "    args:\n",
    "        dest (str) : where you want to create the symbolic link\n",
    "    Returns:\n",
    "        PATH of data directory\n",
    "    \"\"\"\n",
    "    \n",
    "    while not os.path.isdir(src):\n",
    "        src = input(\"Enter path of data dir here\")\n",
    "                \n",
    "    if not os.path.exists('data'):\n",
    "        os.symlink(PATH, 'data')\n",
    "\n",
    "    return 'data'\n",
    "\n",
    "PATH = copy_PATH() \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions to clean raw data file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_resultants(dataDf):\n",
    "    \"\"\"load resultant\n",
    "\n",
    "    Args:\n",
    "        dataDf (pd : df): loaded dataframe with raw data\n",
    "\n",
    "    Returns:\n",
    "        pd : df: loaded df with resultant columns\n",
    "    \"\"\"\n",
    "    \n",
    "    colsNeeded = ['Accel_LN_', 'Accel_WR_', 'Gyro_','Mag_']\n",
    "    \n",
    "    for colRes in colsNeeded:\n",
    "        try:\n",
    "            dataDf['Resultant_' + colRes] = np.sqrt(np.square(dataDf[colRes + 'X_CAL']) + \n",
    "                                            np.square(dataDf[colRes + 'Y_CAL']) + \n",
    "                                            np.square(dataDf[colRes + 'Z_CAL']))\n",
    "        except:\n",
    "            print(\"Issue with %s\" % colRes)\n",
    "\n",
    "    return dataDf\n",
    "\n",
    "def process_rawdata(PATH):\n",
    "    \"\"\"load raw data\n",
    "\n",
    "    Args:\n",
    "        PATH (str): path to the file\n",
    "\n",
    "    Returns:\n",
    "        pd : df: raw data with resultant and timestamp loaded\n",
    "    \"\"\"\n",
    "    #read file\n",
    "    dataDf = pd.read_csv(PATH, sep = '\\t', header=0)\n",
    "    #drop last col with nan\n",
    "    dataDf.dropna(axis=1, inplace = True)\n",
    "    #rename cols\n",
    "    newColNames = [name + '_' + dataDf.iloc[1].values[i] for i,name in enumerate(dataDf.iloc[0].values)]\n",
    "    # change header\n",
    "    dataDf = dataDf.set_axis(newColNames, axis=1, inplace=False)[3:].reset_index(drop=True)\n",
    "    # switch values to float\n",
    "    dataDf = dataDf.astype(float)\n",
    "    # get resultant vals\n",
    "    dataDf = get_resultants(dataDf)\n",
    "    # add time to df\n",
    "    rawTime = file_name_splitter(PATH, type='d')\n",
    "    dataDf['TimeStamp'] = [datetime.datetime.strptime(str(rawTime), \"%Y%m%d%H%M%S\") +\n",
    "                       datetime.timedelta(0,v/102.4) for v in dataDf.index+1]\n",
    "    # return df\n",
    "    return dataDf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# String operations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def file_name_splitter(name, type='d'):\n",
    "    \"\"\"\n",
    "    get file name or the date string\n",
    "    Args:\n",
    "        name ([type]): [description]\n",
    "        type (str, optional): [description]. Defaults to 'd'.\n",
    "\n",
    "    Returns:\n",
    "        str: string or filename\n",
    "    \"\"\"\n",
    "    if type=='d':\n",
    "        item = ''.join([n for n in name if n.isdigit()])\n",
    "        item = int(item)\n",
    "    \n",
    "    else:\n",
    "        item = ''.join([n for n in name if not n.isdigit()])\n",
    "    return item\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# File sanity checker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def check_file_counts(Path = 'data', count = 1):\n",
    "    \"\"\"\n",
    "    level1 cleaning : check number of files, check for duplocites. Count > n will be returned\n",
    "    Args:\n",
    "        Path (str, optional): location tags or raw. Defaults to 'data'.\n",
    "        count (int, optional): frequency limit. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: list of files that need to be checked \n",
    "    \"\"\"\n",
    "    filteredFiles = dict()\n",
    "    for root, dirs,files in os.walk(Path):\n",
    "        files = [file_name_splitter(f,type='s') for f in files]\n",
    "        filesDict = Counter(files)\n",
    "        filesDict = dict(filter(lambda item: item[1]>count, filesDict.items()))\n",
    "        filteredFiles.update(filesDict)\n",
    "    return filteredFiles\n",
    "\n",
    "check_file_counts(Path = 'data/unclean/tag')\n",
    "    \n",
    "def _tyu_verify(arr):\n",
    "    \"\"\"Check if given list has tyu sequence\n",
    "\n",
    "    Args:\n",
    "        arr (list): list of tyu's  \n",
    "\n",
    "    Returns:\n",
    "        bool: bool\n",
    "    \"\"\"\n",
    "    arr = np.array(arr)\n",
    "    arr = arr.reshape(int(len(arr)/3),3)\n",
    "    for item in arr:\n",
    "        if ''.join(item)!='tyu':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_tyu_pattern(Path):\n",
    "    \"\"\"\n",
    "        checks length if length is a multiple of 3 and then checks for tyu pattern\n",
    "    Args:\n",
    "        Path (std): path to file\n",
    "\n",
    "    Returns:\n",
    "        list (n,2): list of filePATHs and problem zipped together \n",
    "    \"\"\"\n",
    "    problemFiles = list()\n",
    "    problemType = list()\n",
    "\n",
    "    for root, dirs,files in os.walk(Path):\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(os.path.join(root, file))\n",
    "            tyuList = df.status.values\n",
    "            if len(tyuList)%3!=0:\n",
    "                problemFiles.append(file)\n",
    "                problemType.append(\"Length\")\n",
    "\n",
    "            elif _tyu_verify(tyuList):\n",
    "                problemFiles.append(file)\n",
    "                problemType.append(\"tyuPattern\")\n",
    "\n",
    "    return list(zip(problemFiles,problemType))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob =check_tyu_pattern(\"data/unclean/tags\")\n",
    "print(len(prob))\n",
    "prob\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#df.iloc[df.index.get_loc(datetime.datetime(2016,2,2),method='nearest')]\n",
    "rawDf, tagDf = _get_raw_tag_df('data/unclean/raw/a','20210911110355a_le_sit.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawDf.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\n",
    "def _get_raw_tag_df(root, file):\n",
    "    \"\"\" Load dfs\n",
    "\n",
    "    Args:\n",
    "        root (str): root name of file\n",
    "        file (str): file name\n",
    "\n",
    "    Returns:\n",
    "        (df, df): 2 raw and tag dfs \n",
    "    \"\"\"\n",
    "    filePathRaw = os.path.join(root, file)\n",
    "    filePathTag = os.path.join(\"data/unclean/tags/\" + root[-1], file_name_splitter(file, type='s'))\n",
    "    rawDf = process_rawdata(filePathRaw)\n",
    "    tagDf = pd.read_csv(filePathTag)\n",
    "    return rawDf, tagDf\n",
    "\n",
    "def _pull_pid(name):\n",
    "    name = file_name_splitter(name,type='s')\n",
    "    name = name.split('_')[0]\n",
    "    return name\n",
    "\n",
    "def _pull_description(name):\n",
    "    \"\"\" get the activity description\n",
    "    Args:\n",
    "        name (str): fileName \n",
    "    Returns:\n",
    "        str: activity description\n",
    "    \"\"\"\n",
    "    name = file_name_splitter(name,type='s')\n",
    "    desc = name.strip('.csv').split(\"_\")[1:]\n",
    "    desc = '_'.join(desc)\n",
    "    return desc\n",
    "\n",
    "def _pull_label(name):\n",
    "    \"\"\"get the activity description\n",
    "\n",
    "   Args:\n",
    "        name (str): fileName \n",
    "\n",
    "    Returns:\n",
    "        str: activity label (1,0)\n",
    "    \"\"\"\n",
    "    name = file_name_splitter(name,type='s')\n",
    "    if name.split('_')[1] in ['le', 're', 'n', 'm']:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    return label\n",
    "\n",
    "def _pull_feature(root, file, sliceLen):\n",
    "    \"\"\" takes a single df and extracts features\n",
    "\n",
    "    Args:\n",
    "        root (str): root name of file\n",
    "        file (str): file name\n",
    "\n",
    "    Returns:\n",
    "        [type]: features df either static or dynamic\n",
    "    \"\"\"\n",
    "    feats =list()\n",
    "    rawDf, tagDf = _get_raw_tag_df(root, file)\n",
    "    # filter touch points\n",
    "    tagDf = tagDf[tagDf[\"status\"]==\"y\"]\n",
    "\n",
    "    fileParts = file.strip(\".csv\").split(\"_\")\n",
    "\n",
    "    feats = list()\n",
    "    if fileParts[2]==fileParts[1]:\n",
    "        feats = __type_static(rawDf,tagDf, sliceLen)\n",
    "    else:\n",
    "        feats = __type_dynamic(rawDf,tagDf, sliceLen)\n",
    "\n",
    "    return feats\n",
    "\n",
    "def __type_dynamic(rawDf, tagDf, sliceLen):\n",
    "    \"\"\" for dynamic activities\n",
    "\n",
    "    Args:\n",
    "        rawDf (df): raw data\n",
    "        tagDf (df): tags data\n",
    "\n",
    "    Returns:\n",
    "        features\n",
    "    \"\"\"\n",
    "    feats = list()\n",
    "    for tPoint in tagDf.time.values:\n",
    "        try:\n",
    "            index = rawDf.iloc[rawDf.set_index('TimeStamp').index.get_loc(tPoint ,method='nearest')].name\n",
    "            \n",
    "            #feat = rawDf.Resultant_Accel_LN_[index-30:index+20].values\n",
    "            feat = rawDf[[\"Accel_LN_X_CAL\",\"Accel_LN_Y_CAL\",\"Accel_LN_Z_CAL\",\n",
    "              \"Resultant_Accel_LN_\",\n",
    "               \"Gyro_X_CAL\", \"Gyro_Y_CAL\", \"Gyro_Z_CAL\",\n",
    "                \"Resultant_Gyro_\"]][index-sliceLen:index].values#.flatten()\n",
    "            \n",
    "            if feat.shape==(sliceLen,8):\n",
    "                feats.append(feat)\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"dynamic feats shape {}\".format(np.array(feats).shape))\n",
    "    return feats\n",
    "\n",
    "def __type_static(rawDf,tagDf, sliceLen):\n",
    "    \"\"\" for static activities\n",
    "\n",
    "    Args:\n",
    "        rawDf (df): raw data\n",
    "        tagDf (df): tags data\n",
    "\n",
    "    Returns:\n",
    "        features\n",
    "    \"\"\"\n",
    "    feats = list()\n",
    "    length = len(rawDf)\n",
    "    rawDf = rawDf[300:length-300]\n",
    "    \n",
    "    length = sliceLen*20#len(rawDf) - len(rawDf)%50\n",
    "    rawDf = rawDf[:length]\n",
    "\n",
    "    #feats = rawDf.Resultant_Accel_LN_.values.reshape(int(length/50),50)\n",
    "    feats = rawDf[[\"Accel_LN_X_CAL\",\"Accel_LN_Y_CAL\",\"Accel_LN_Z_CAL\",  \n",
    "    \"Resultant_Accel_LN_\", \"Gyro_X_CAL\",\n",
    "     \"Gyro_Y_CAL\", \"Gyro_Z_CAL\",\n",
    "      \"Resultant_Gyro_\"]].values.reshape(int(length/sliceLen),sliceLen,8)[:20]#.flatten().reshape(int(length/50),150)\n",
    "    \n",
    "    print(\"static feats shape {}\".format(np.array(feats).shape))\n",
    "    feats = list(feats)\n",
    "    #print(\"static feats length %d\" %len(feats))\n",
    "    return feats\n",
    "\n",
    "\n",
    "for ext in tqdm.tqdm([\"80_8\"]):\n",
    "    sliceLen = int(ext.split(\"_\")[0])\n",
    "\n",
    "    features = list()\n",
    "    labels = list()\n",
    "    descriptions = list()\n",
    "    pids = list()\n",
    "    for root,dirs,files in tqdm.tqdm(os.walk(\"data/unclean/raw\")):\n",
    "        for file in files:\n",
    "            rawDf, tagDf = _get_raw_tag_df(root, file)\n",
    "            \n",
    "            description = _pull_description(file)\n",
    "            label = _pull_label(file)\n",
    "            feature = _pull_feature(root,file, sliceLen)\n",
    "            pid = _pull_pid(file)\n",
    "            descriptions.extend([description]*len(feature))\n",
    "            labels.extend([label]*len(feature))\n",
    "            pids.extend([pid]*len(feature))\n",
    "            features.extend(feature)\n",
    "            #break\n",
    "\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    descriptions = np.array(descriptions)\n",
    "    pids = np.array(pids)\n",
    "    labels_descriptions = np.hstack((pids.reshape(-1,1),descriptions.reshape(-1,1),labels.reshape(-1,1)))\n",
    "\n",
    "\n",
    "    s = features.shape\n",
    "    feat2D = features.reshape(s[0], s[1]*s[2])\n",
    "    np.savetxt(\"features{}.txt\".format(ext),feat2D)\n",
    "    np.savetxt(\"labels{}.txt\".format(ext),labels_descriptions,fmt = \"%s %s %s\")\n",
    "\n",
    "\n",
    "    meta = meta = {\"columns\" : [\"Accel_LN_X_CAL\",\"Accel_LN_Y_CAL\",\"Accel_LN_Z_CAL\",  \"Resultant_Accel_LN_\", \"Gyro_X_CAL\", \"Gyro_Y_CAL\", \"Gyro_Z_CAL\", \"Resultant_Gyro_\"],\n",
    "        \"timeLength\" : \"0.{} seconds\".format(int(ext.split(\"_\")[0])/100),\n",
    "        \"instanceSegmented\" : \"{} samples going back from key press y\".format(ext.split(\"_\")[0]),\n",
    "        \"cols\" : 8,\n",
    "        \"length\" : ext.split(\"_\")[0]\n",
    "        }\n",
    "\n",
    "    with open(\"data/dataset/rawExtract/meta{}.json\".format(ext), 'w') as jsonFile:\n",
    "        json.dump(meta, jsonFile)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_916436/491436087.py:13: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  rawDf = process_rawdata(filePathRaw)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (16, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (27, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (22, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (20, 80, 8)\n",
      "dynamic feats shape (13, 80, 8)\n",
      "dynamic feats shape (14, 80, 8)\n",
      "dynamic feats shape (15, 80, 8)\n",
      "dynamic feats shape (14, 80, 8)\n",
      "dynamic feats shape (16, 80, 8)\n",
      "dynamic feats shape (15, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (14, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (16, 80, 8)\n",
      "dynamic feats shape (15, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (27, 80, 8)\n",
      "dynamic feats shape (30, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (20, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (27, 80, 8)\n",
      "dynamic feats shape (20, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (21, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (21, 80, 8)\n",
      "static feats shape (20, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (16, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (16, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (14, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (20, 80, 8)\n",
      "dynamic feats shape (21, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (15, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (10, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (10, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (16, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "static feats shape (20, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (19, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (17, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "11it [00:42,  3.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dynamic feats shape (18, 80, 8)\n",
      "dynamic feats shape (18, 80, 8)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:44<00:00, 44.46s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s = features.shape\n",
    "features[0][0]#.reshape(s[0], s[1]*s[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s = features.shape\n",
    "features.reshape(s[0], s[1]*s[2]).reshape(s[0], s[1], s[2])[0][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initi\n",
    "    # alized.\n",
    "    print('Could not initialize the tensorflow gpu')\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input = layers.Input(shape = (50,3))\n",
    "model = layers.Conv1D(50, kernel_size = 3, activation='relu')(input)\n",
    "model = layers.GlobalAveragePooling1D()(model)\n",
    "model = layers.Flatten()(model)\n",
    "\n",
    "output = layers.Dense(1)(model)\n",
    "model = tf.keras.Model(inputs=[input], outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(loss = loss, optimizer=optimizer, metrics = ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(X_Train,y_Train, epochs=200,validation_split=0.2,shuffle=True)\n",
    "preds=model.predict(X_Test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = [1 if pp>0 else 0 for pp in preds]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(p, y_Test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for root,dirs,files in tqdm.tqdm(os.walk(\"data/unclean/raw\")):\n",
    "#     for file in files:\n",
    "#         rawDf, _ = _get_raw_tag_df(root, file)\n",
    "#         description = _pull_description(file)\n",
    "#         label = _pull_label(file)\n",
    "#         feature = _pull_feature(root,file)\n",
    "#         pid = _pull_pid(file)\n",
    "#         descriptions.extend([description]*len(feature))\n",
    "#         labels.extend([label]*len(feature))\n",
    "#         pids.extend([pid]*len(feature))\n",
    "#         features.extend(feature)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for i,feature in enumerate(features):\n",
    "#     if len(feature)!=50:\n",
    "#         print(len(feature))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label, description"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.array(features).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fileParts = file.strip(\".csv\").split(\"_\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(features, labels, random_state=43, test_size=0.2, shuffle=True)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "\n",
    "rf.fit(X_Train, y_Train)\n",
    "\n",
    "rf.score(X_Test,y_Test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.array(features).shape, np.array(labels).shape, np.array(descriptions).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Counter(descriptions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3,5,10],\n",
    "    'min_samples_leaf': [15,25, 40],\n",
    "    'min_samples_split': [20,40,60],\n",
    "    'n_estimators': [50,100,200,300]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, verbose=3, n_jobs=-1, cv=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid.fit(X_Train, y_Train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "select = grid.best_estimator_\n",
    "select.fit(X_Train,y_Train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "select.score(X_Test, y_Test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_Test, select.predict(X_Test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load raw data and tags Files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fileName = \"a_le_sit.csv\"\n",
    "tagsDf = pd.read_csv(\"../data/tags/b/b_m_sit.csv\", index_col=[0])\n",
    "dataDf = process_rawdata(\"../data/raw/b/20210910171401b_m_sit.csv\")\n",
    "tagsDf['time'] = pd.to_datetime(tagsDf.time) + datetime.timedelta(0,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datetime\n",
    "\n",
    "datetime.datetime.strptime('20210910105115', \"%Y%m%d%H%M%S\") + datetime.timedelta(0,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataDf['TimeStamp'] = [datetime.datetime.strptime('20210910105115', \"%Y%m%d%H%M%S\") +\n",
    "                       datetime.timedelta(0,v/51) for v in dataDf.index+1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize = (7,5),dpi=120)\n",
    "\n",
    "#plt.plot(dataDf.TimeStamp[2000:3000],dataDf.Resultant_Accel_LN_[:1000])\n",
    "\n",
    "plt.plot(dataDf.TimeStamp[2000:3000],dataDf.Resultant_Accel_LN_[2000:3000], color='black')\n",
    "\n",
    "# plt.plot(dataDf.TimeStamp[2000:3000],dataDf.Accel_LN_X_CAL[2000:3000], label = 'x-Accel')\n",
    "# plt.plot(dataDf.TimeStamp[2000:3000],dataDf.Accel_LN_Y_CAL[2000:3000], label = 'y-Accel')\n",
    "# plt.plot(dataDf.TimeStamp[2000:3000],dataDf.Accel_LN_Z_CAL[2000:3000], label = 'z-Accel')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# d = data['Date'].values\n",
    "# plt.fill_between(d, data['A'], data['B'],\n",
    "#                 where=data['A'] >= data['B'],\n",
    "#                 facecolor='green', alpha=0.2, interpolate=True)\n",
    "\n",
    "\n",
    "for i,bar in enumerate(tagsDf.values.reshape(27,3,2)[8:13]):\n",
    "    times = np.take(bar,0, axis=1)\n",
    "    times = [t - datetime.timedelta(0,1) for t in times]\n",
    "    a = times[0]\n",
    "    b = times[1]\n",
    "    vals = dataDf.Resultant_Accel_LN_[2000:3000]\n",
    "    #vals = [0,25]\n",
    "    if i==0:\n",
    "        plt.fill_between([times[0],times[1]], np.min(vals), np.max(vals), alpha =0.6, color = 'gray', label = \"transition to touch\")\n",
    "        plt.fill_between([times[1],times[2]], np.min(vals), np.max(vals), alpha =0.6, color = 'pink', label = \"touch left eye\")\n",
    "    else:\n",
    "        plt.fill_between([times[0],times[1]], np.min(vals), np.max(vals), alpha =0.6, color = 'gray')\n",
    "        plt.fill_between([times[1],times[2]], np.min(vals), np.max(vals), alpha =0.6, color = 'pink')\n",
    "        \n",
    "plt.xlabel(\"Time (HH:MM:SS)\")\n",
    "    #plt.fill_between([times[1],times[2]], np.min(vals), np.max(vals), alpha =0.6, color = 'yellow')\n",
    "\n",
    "    # #     plt.fill_between(np.take(bar,0))\n",
    "    \n",
    "# #     print(np.take(bar,0))\n",
    "# #     pos= np.sum(np.take(bar,0))\n",
    "# #     print(pos)\n",
    "#     plt.bar(np.take(bar,0), 27.5, datetime.timedelta(0,20))\n",
    "    \n",
    "#     val= [max_val]\n",
    "#     width = [bar[2][0]-bar[0][0]]\n",
    "#     ax2.bar(pos,val,width, color = 'black', alpha = 0.1)\n",
    "plt.legend()\n",
    "#plt.savefig(\"r.png\")\n",
    "plt.show()\n",
    "#plt.bar()\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for val in tagsDf.values.reshape(27,3,2)[:4]:\n",
    "    print(np.take(val,0, axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('facePy': conda)"
  },
  "interpreter": {
   "hash": "c39a2619ac667b8116ef4989c7433e85b59243eb4a825554e252b96c371cd590"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}